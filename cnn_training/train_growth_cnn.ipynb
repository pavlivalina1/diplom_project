{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "data_path = \"C:\\\\Users\\\\ACER\\\\PycharmProjects\\\\pythonProject17\\\\data\\\\\"\n",
    "images_orig = np.load(data_path + \"Sunflower_Stages.npy\", allow_pickle=True)\n",
    "labels_orig = np.load(data_path + \"Sunflower_Stages_Labels.npy\", allow_pickle=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_classes = len(np.unique(labels_orig))\n",
    "example_images = {}\n",
    "for img, label in zip(images_orig, labels_orig):\n",
    "    label = int(label)\n",
    "    if label not in example_images:\n",
    "        example_images[label] = img\n",
    "    if len(example_images) == num_classes:\n",
    "        break\n",
    "\n",
    "# Побудова графіка\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i in range(num_classes):\n",
    "    img = example_images[i]\n",
    "    img = img[..., ::-1]\n",
    "    plt.subplot(1, num_classes, i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Стадія {i + 1}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Приклади зображень до трансформацій для кожного класу\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "images_orig = images_orig.astype(np.float32) / 255.0\n",
    "labels_orig = labels_orig.reshape(-1)\n",
    "\n",
    "print(f\"Форма зображень: {images_orig.shape}\")\n",
    "print(f\"Форма міток: {labels_orig.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "images = images_orig\n",
    "labels = labels_orig"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class SunflowerDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],   # mean\n",
    "                         [0.229, 0.224, 0.225])   # std\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],   # mean\n",
    "                         [0.229, 0.224, 0.225])   # std\n",
    "])\n",
    "\n",
    "total_size = len(images)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "indices = list(range(total_size))\n",
    "train_indices, val_indices, test_indices = random_split(indices, [train_size, val_size, test_size])\n",
    "\n",
    "train_data = SunflowerDataset([images[i] for i in train_indices], [labels[i] for i in train_indices], transform=train_transform)\n",
    "val_data = SunflowerDataset([images[i] for i in val_indices], [labels[i] for i in val_indices], transform=val_test_transform)\n",
    "test_data = SunflowerDataset([images[i] for i in test_indices], [labels[i] for i in test_indices], transform=val_test_transform)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "print(f\"Train size: {len(train_data)}, Validation size: {len(val_data)}, Test size: {len(test_data)}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def show_images(loader, num_images=5):\n",
    "    data_iter = iter(loader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = np.clip(img, 0, 1)\n",
    "        img = img[..., ::-1]\n",
    "\n",
    "        label = labels[i].item()\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"Stage: {label+1}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_images(val_loader)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "for param in mobilenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, num_classes)\n",
    "\n",
    "for param in mobilenet.classifier[1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(mobilenet)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "for param in efficientnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "efficientnet._fc = nn.Linear(efficientnet._fc.in_features, num_classes)\n",
    "\n",
    "for param in efficientnet._fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(efficientnet)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(mobilenet.classifier[1].parameters(), lr=1e-4)\n",
    "# optimizer = optim.Adam(efficientnet._fc.parameters(), lr=1e-4)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "inference_times_ms = []\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "patience = 5\n",
    "best_val_acc = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    mobilenet.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mobilenet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # --- ОЦІНКА НА ВАЛІДАЦІЇ ---\n",
    "    mobilenet.eval()\n",
    "    val_correct, val_total = 0, 0\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    inference_time_epoch = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "\n",
    "            start_infer = time.time()\n",
    "            outputs = mobilenet(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            end_infer = time.time()\n",
    "\n",
    "            inference_time_epoch += (end_infer - start_infer)\n",
    "\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            val_preds.extend(predicted.cpu().numpy())\n",
    "            val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    # --- ДОДАТКОВІ МЕТРИКИ ---\n",
    "    precision = precision_score(val_true, val_preds, average='macro')\n",
    "    recall = recall_score(val_true, val_preds, average='macro')\n",
    "    f1 = f1_score(val_true, val_preds, average='macro')\n",
    "    avg_infer_ms = inference_time_epoch * 1000 / len(val_loader.dataset)\n",
    "\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    inference_times_ms.append(avg_infer_ms)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Acc: {val_acc:.2f}%, \"\n",
    "          f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}, \"\n",
    "          f\"Infer time: {avg_infer_ms:.2f} ms\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nТренування завершено за {end_time - start_time:.2f} секунд\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].plot(range(1, len(train_losses)+1), train_losses, label='Train Loss', color='blue')\n",
    "axes[0].set_title(\"train/loss\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(range(1, len(train_accuracies)+1), train_accuracies, label='Train Accuracy', color='green')\n",
    "axes[1].plot(range(1, len(val_accuracies)+1), val_accuracies, label='Val Accuracy', color='orange')\n",
    "axes[1].set_title(\"metrics/accuracy\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].plot(range(1, len(precision_list)+1), precision_list, label='Precision', color='darkgreen')\n",
    "axes[2].set_title(\"metrics/precision\")\n",
    "axes[2].grid(True)\n",
    "\n",
    "axes[3].plot(range(1, len(recall_list)+1), recall_list, label='Recall', color='darkred')\n",
    "axes[3].set_title(\"metrics/recall\")\n",
    "axes[3].grid(True)\n",
    "\n",
    "axes[4].plot(range(1, len(f1_list)+1), f1_list, label='F1 Score', color='purple')\n",
    "axes[4].set_title(\"metrics/F1\")\n",
    "axes[4].grid(True)\n",
    "\n",
    "axes[5].plot(range(1, len(inference_times_ms)+1), inference_times_ms, label='Inference time', color='teal')\n",
    "axes[5].set_title(\"metrics/inference_time (ms)\")\n",
    "axes[5].grid(True)\n",
    "\n",
    "axes[6].axis(\"off\")\n",
    "axes[7].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Криві метрик для EfficientNet-B0\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_score = []\n",
    "class_names = [\"Stage 1\", \"Stage 2\", \"Stage 3\", \"Stage 4\", \"Stage 5\", \"Stage 6\", \"Stage 7\", \"Stage 8\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "        y_score.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_true = label_binarize(y_true, classes=list(range(num_classes)))  # One-hot\n",
    "y_score = np.array(y_score)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "colors = plt.cm.get_cmap(\"tab10\", num_classes)\n",
    "\n",
    "average_precisions = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_true[:, i], y_score[:, i])\n",
    "    ap = average_precision_score(y_true[:, i], y_score[:, i])\n",
    "    average_precisions.append(ap)\n",
    "    plt.plot(recall, precision, label=f\"Stage {i+1} (AP={ap:.2f})\", color=colors(i))\n",
    "\n",
    "mean_ap = np.mean(average_precisions)\n",
    "plt.plot([0, 1], [mean_ap, mean_ap], \"k--\", label=f\"Mean AP={mean_ap:.3f}\")\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall curve (per class)\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Точність моделі на тестових даних: {accuracy:.2f}%\")\n",
    "\n",
    "evaluate_model(model, test_loader)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classification_metrics(model, test_loader, class_names):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "\n",
    "classification_metrics(model, test_loader, class_names)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model.state_dict(), \"sunflower_growth_model_resnet.pth\")\n",
    "\n",
    "# print(\"Модель збережено!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "num_classes = 8\n",
    "\n",
    "mobilenet = models.mobilenet_v2(pretrained=False)\n",
    "mobilenet.classifier[1] = torch.nn.Linear(mobilenet.classifier[1].in_features, num_classes)\n",
    "mobilenet.load_state_dict(torch.load(\"models/sunflower_growth_model_mobilenet3.pth\", map_location=\"cpu\"))\n",
    "mobilenet.eval()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    img = img_tensor.numpy().transpose((1, 2, 0))  # CHW -> HWC\n",
    "    img = (img * imagenet_std) + imagenet_mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return img\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "class_names = [\"Stage 1\", \"Stage 2\", \"Stage 3\", \"Stage 4\", \"Stage 5\", \"Stage 6\", \"Stage 7\", \"Stage 8\"]\n",
    "\n",
    "def show_class_examples(model, dataloader, class_names):\n",
    "    model.eval()\n",
    "    shown_classes = set()\n",
    "    images_to_show = []\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for img, true_label, pred_label in zip(inputs, labels, preds.cpu()):\n",
    "                if true_label.item() not in shown_classes:\n",
    "                    shown_classes.add(true_label.item())\n",
    "                    images_to_show.append(img.cpu())\n",
    "                    true_labels.append(true_label.item())\n",
    "                    predicted_labels.append(pred_label.item())\n",
    "                if len(shown_classes) == len(class_names):\n",
    "                    break\n",
    "            if len(shown_classes) == len(class_names):\n",
    "                break\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for idx, img in enumerate(images_to_show):\n",
    "        plt.subplot(2, len(images_to_show)//2 + 1, idx + 1)\n",
    "        img = denormalize(img)\n",
    "        img = img[:, :, ::-1]\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Справжній: {class_names[true_labels[idx]]}\\nПередбачено: {class_names[predicted_labels[idx]]}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "show_class_examples(mobilenet, test_loader, class_names)\n",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
